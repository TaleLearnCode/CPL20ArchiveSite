@page
@model CPL20Archive.Pages.Sessions._2047.IndexModel
@{
}
    <div class="top-title-area bg-img-charcoal-eticket">
      <div class="container">
        <h1 class="title-page">Session Details</h1>
      </div>
    </div>
    <div class="gap"></div>
    <div class="container">
      <div class="row">
        <div class="span3">
          <aside class="sidebar-left">
            <br />
            <h5 class="SessionDetails">Topic(s)</h5>
           <a asp-page="/Sessions/Topic_AppDev">Application Development</a><br />
            <br />
          </aside>
        </div>
        <div class="span9">
          <h2 id="MainContent_MainContent_SessionTitle" class="SessionDetails">The Quality Dashboard</h2>
          <h5 id="MainContent_MainContent_SessionType" class="SessionDetails">Regular Session</h5>
          <br />
         <iframe width="560" height="315" src="https://www.youtube.com/embed/L_T1Ty3UF5Y" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen></iframe>
          You’ve got thousands of automated tests running, multiple test and coverage reports and logs – but you can’t see the forest from the trees. The problem is you don’t know: Is it safe to release? With refined, specific metrics, you can define reports (or dashboard) that tell you the real quality of the product. You can then decide what to do about it.

This is a case-study of building a quality dashboard with metrics and reports that matter for an application with hundreds of APIs, and multiple front-ends. Some features were better covered than others, but what that coverage meant was vague. The dashboard was built, collecting information from multiple sources – test reports and coverage reports from Jenkins, custom logs that were farmed for information, SonarQube and more. We then added some “brains” to show the analyzed metrics, in terms of covered and uncovered test cases, test quality and more. We then presented a confidence level calculated from the metrics. The effort was done by developers, quality advisors, dev-ops people and others. This session is about this project.

The dashboard helps managers see what features are ready, where the gaps are, and gave back feedback to the developers how well their tests are working for them. With this session you may be inspired to build a quality reports that tell you how well your team is doing.

          <hr />
          <div class="row row-wrap">
            <div class="span3">
              <div class="thumb center">
                <div class="thumb-header">
                  <a class="hover-img" href="http://codepalousa.com/SpeakerDetails/69431EE1-4C39-48D8-BB92-4189366BD577">
                    <img src="https://greeneventstechnology.azureedge.net/cpl20/speakers/Gil_Zilberfeld.png" alt="Gil Zilberfeld" title="Gil Zilberfeld" />
                  </a>
                </div>
                <div class="thumb-caption">
                  <h5 class="thumb-title"><a href="http://codepalousa.com/SpeakerDetails/69431EE1-4C39-48D8-BB92-4189366BD577">Gil Zilberfeld</a></h5>
                  <p class="thumb-meta"><br /></p>
                </div>
              </div>
            </div>
          </div>
        </div>
      </div>
      <div class="gap"></div>
    </div>
